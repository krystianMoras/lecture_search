{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycozo.client import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read docs\n",
    "paths = [\n",
    "    r\"../assets/text/da-lec1-notes.txt\",\n",
    "    r\"../assets/text/da-lec2-notes.txt\",\n",
    "    r\"../assets/text/da-lec3-notes.txt\",\n",
    "    r\"../assets/text/da-lec4-notes.txt\",\n",
    "    r\"../assets/text/da-lec5-notes.txt\",\n",
    "    r\"../assets/text/da-lec6-notes.txt\",\n",
    "    r\"../assets/text/da-lec7-notes.txt\",\n",
    "    r\"../assets/text/da-lec8-notes.txt\",\n",
    "    r\"../assets/text/da-lec9-notes.txt\",\n",
    "    r\"../assets/text/da-lec10-notes.txt\",\n",
    "    r\"../assets/text/da-lec11-notes.txt\",\n",
    "    r\"../assets/text/da-lec12-notes.txt\",\n",
    "]\n",
    "from pathlib import Path\n",
    "\n",
    "paths = [Path(p) for p in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "document_relation = pd.DataFrame(\n",
    "    columns=[\"document_name\",\"document_path\"],\n",
    "    data=[(path.name, path) for i, path in enumerate(paths)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client('sqlite', 'file.db')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a document path - document id relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  status\n",
       "0     OK"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.run(\n",
    "    \"\"\"\n",
    "    :create document {document_name => document_path}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document_name, document_path in document_relation.values:\n",
    "    client.run(\"\"\"\n",
    "    ?[document_name, document_path] <- [[$document_name, $document_path]]\n",
    "    :put document {document_name => document_path}\n",
    "    \"\"\",{\"document_name\":str(document_name),\"document_path\":str(document_path)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  status\n",
       "0     OK"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.run(\"\"\"\n",
    "    :create sentence {sentence_id, paragraph_id, doc_name => sentence} \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  status\n",
       "0     OK"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.run(\"\"\"\n",
    "    :create phrases {phrase:String, doc_name:String, paragraph_id:Int?}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['da-lec1-notes.txt', 'da-lec2-notes.txt', 'da-lec3-notes.txt', 'da-lec4-notes.txt', 'da-lec5-notes.txt', 'da-lec6-notes.txt', 'da-lec7-notes.txt', 'da-lec8-notes.txt', 'da-lec9-notes.txt', 'da-lec10-notes.txt', 'da-lec11-notes.txt', 'da-lec12-notes.txt'])"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read phrases \n",
    "import json\n",
    "with open(r\"../data/results_decision_analysis_slides.json\",\"r\") as f:\n",
    "    phrases = json.load(f)\n",
    "phrases = {k+\".txt\":v for k,v in phrases.items()}\n",
    "phrases.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_dict = {\n",
    "    \"sentence\": {\n",
    "        \"headers\": [\"sentence_id\", \"paragraph_id\", \"doc_name\", \"sentence\"],\n",
    "        \"rows\": [],\n",
    "    }\n",
    "}\n",
    "for path in paths:\n",
    "    with open(path, 'r') as f:\n",
    "        paragraphs = f.read().splitlines()\n",
    "    doc_name = path.name\n",
    "    doc_path = path\n",
    "    for paragraph_id,paragraph in enumerate(paragraphs):\n",
    "        if len(paragraph) > 0:\n",
    "            sents = sent_tokenize(paragraph)\n",
    "            for sentence_id, sent in enumerate(sents):\n",
    "                sentence_dict[\"sentence\"][\"rows\"].append(\n",
    "                    [sentence_id, paragraph_id, doc_name, sent]\n",
    "                )\n",
    "\n",
    "# sentence_dict\n",
    "client.import_relations(sentence_dict)\n",
    "\n",
    "# tx.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  status\n",
       "0     OK"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.run(\"\"\"\n",
    "    ::fts create sentence:phrases {\n",
    "    extractor: sentence,\n",
    "    tokenizer: Simple,\n",
    "    filters: [Lowercase,AlphaNumOnly, Stemmer('English')],\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "phrases: 100%|██████████| 1984/1984 [00:08<00:00, 225.66it/s]\n"
     ]
    }
   ],
   "source": [
    "phrase_dict = {\n",
    "    \"phrases\": {\n",
    "        \"headers\": [\"phrase\", \"doc_name\", \"paragraph_id\"],\n",
    "        \"rows\": []\n",
    "    }\n",
    "}\n",
    "all_phrases = [phrase for doc_phrases in phrases.values() for phrase in doc_phrases]\n",
    "all_phrases = list(set(all_phrases))\n",
    "for original_phrase in tqdm(all_phrases,desc=\"phrases\",total=len(all_phrases)):\n",
    "    #replace non alphanumeric characters with space\n",
    "    phrase = \"\".join([c if c.isalnum() else \" \" for c in original_phrase])\n",
    "    # split phrase into 2 word spans\n",
    "    phrase = phrase.split()\n",
    "    span = \" \".join(phrase[0:2])\n",
    "\n",
    "    total = client.run(\"\"\"\n",
    "        ?[paragraph_id, doc_name] := ~sentence:phrases {paragraph_id,doc_name, sentence |\n",
    "            query: $query,\n",
    "            k: 1000\n",
    "        }\n",
    "        \"\"\", {\"query\": f\"NEAR/1({span})\"})\n",
    "    \n",
    "    for i in range(1,len(phrase)-1):\n",
    "        span = \" \".join(phrase[i:i+2])\n",
    "        results = client.run(\"\"\"\n",
    "        ?[paragraph_id, doc_name] := ~sentence:phrases {paragraph_id,doc_name, sentence |\n",
    "            query: $query,\n",
    "            k: 1000\n",
    "        }\n",
    "        \"\"\", {\"query\": f\"NEAR/1({span})\"})\n",
    "        total = pd.merge(total,results,how=\"inner\")\n",
    "    for paragraph_id, doc_name in total.values:\n",
    "        phrase_dict[\"phrases\"][\"rows\"].append([original_phrase, doc_name, paragraph_id])\n",
    "        \n",
    "client.import_relations(phrase_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_name</th>\n",
       "      <th>paragraph_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>da-lec2-notes.txt</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>da-lec2-notes.txt</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>da-lec2-notes.txt</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>da-lec3-notes.txt</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            doc_name  paragraph_id\n",
       "0  da-lec2-notes.txt             3\n",
       "1  da-lec2-notes.txt             4\n",
       "2  da-lec2-notes.txt            30\n",
       "3  da-lec3-notes.txt            35"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.run(\"\"\"\n",
    "    ?[doc_name, paragraph_id] := *phrases[\"worst class\", doc_name, paragraph_id]\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/kryst/Documents/Personal/university/ai_sem6/nlp/testing')"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_path = Path(r\"C:\\Users\\kryst\\Documents\\Personal\\university\\ai_sem6\\nlp\\testing\")\n",
    "notes_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'binary classification'"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paragraphs(original_phrase):\n",
    "    dataframe = client.run(\"\"\"\n",
    "        paragraphs[doc_name, paragraph_id] := *phrases[$phrase, doc_name, paragraph_id],\n",
    "        ?[sentence,sentence_id,paragraph_id,doc_name] := *sentence[sentence_id, paragraph_id, doc_name, sentence],paragraphs[doc_name, paragraph_id]\n",
    "        :order doc_name, paragraph_id, sentence_id\n",
    "        \"\"\",{\"phrase\":original_phrase})\n",
    "    # for each combination of paragraph_id and doc_name, get the paragraph\n",
    "    return dataframe.groupby([\"doc_name\",\"paragraph_id\"]).agg({\"sentence\":lambda x: \" \".join(x)})\n",
    "    \n",
    "    \n",
    "df = get_paragraphs(\"best class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('da-lec2-notes.txt', 3),\n",
       "  sentence     The basic idea underlying the sorting method ...\n",
       "  Name: (da-lec2-notes.txt, 3), dtype: object),\n",
       " (('da-lec2-notes.txt', 32),\n",
       "  sentence     Let us check the results of our study while m...\n",
       "  Name: (da-lec2-notes.txt, 32), dtype: object),\n",
       " (('da-lec3-notes.txt', 35),\n",
       "  sentence     The question is how to translate assignment e...\n",
       "  Name: (da-lec3-notes.txt, 35), dtype: object)]"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_name</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">da-lec2-notes.txt</th>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>da-lec3-notes.txt</th>\n",
       "      <th>35</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                sentence\n",
       "doc_name          paragraph_id          \n",
       "da-lec2-notes.txt 3                 True\n",
       "                  32                True\n",
       "da-lec3-notes.txt 35                True"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"doc_name\",\"paragraph_id\"]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "notes: 100%|██████████| 1984/1984 [04:06<00:00,  8.06it/s]\n"
     ]
    }
   ],
   "source": [
    "for original_phrase in tqdm(all_phrases, desc=\"notes\", total=len(all_phrases)):\n",
    "    md_text = \"\"\n",
    "    paragraphs = get_paragraphs(original_phrase)\n",
    "    for paragraph_description,paragraph in paragraphs.iterrows():\n",
    "        md_text += f\"\\n\\n `document : {paragraph_description[0]} slide: {paragraph_description[1]}`\"\n",
    "        md_text += f\"\\n\\n {paragraph['sentence']}\"\n",
    "    md_text += \"\\n\\n## See also:\"\n",
    "    adjacent = client.run(\"\"\"\n",
    "        ?[phrase] := *phrases[phrase, doc_name, paragraph_id], *phrases[$phrase, doc_name, paragraph_id], phrase!= $phrase\n",
    "        \"\"\",{\"phrase\":original_phrase}).values\n",
    "    for phrase in adjacent:\n",
    "        md_text += f\"\\n[[{phrase[0]}]]\"\n",
    "    cleaned_phrase = \"\".join([c if c.isalnum() else \" \" for c in original_phrase])\n",
    "    with open(notes_path / f\"{cleaned_phrase}.md\",\"w\") as f:\n",
    "        f.write(md_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
