{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycozo.client import Client\n",
    "\n",
    "cozo_client = Client(\"sqlite\", r\"C:\\Users\\kryst\\Documents\\Artificial Intelligence\\Artificial Intelligence - sem6\\courses\\cozo_test.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>relations</th>\n",
       "      <th>config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>full_text_search</td>\n",
       "      <td>fts</td>\n",
       "      <td>[sentences:full_text_search]</td>\n",
       "      <td>{'extractor': 'sentence', 'tokenizer': {'args'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name type                     relations  \\\n",
       "0  full_text_search  fts  [sentences:full_text_search]   \n",
       "\n",
       "                                              config  \n",
       "0  {'extractor': 'sentence', 'tokenizer': {'args'...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cozo_client.run(\"::indices sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  status\n",
       "0     OK"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cozo_client.run(\"::hnsw drop passages:semantic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "QueryException",
     "evalue": "index full_text_search for relation sentences not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mQueryException\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cozo_client\u001b[39m.\u001b[39;49mrun(\u001b[39m\"\u001b[39;49m\u001b[39m::index drop sentences:full_text_search\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\kryst\\miniconda3\\envs\\tf\\lib\\site-packages\\pycozo\\client.py:112\u001b[0m, in \u001b[0;36mClient.run\u001b[1;34m(self, script, params)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client_request(script, params)\n\u001b[0;32m    111\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 112\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedded_request(script, params)\n",
      "File \u001b[1;32mc:\\Users\\kryst\\miniconda3\\envs\\tf\\lib\\site-packages\\pycozo\\client.py:96\u001b[0m, in \u001b[0;36mClient._embedded_request\u001b[1;34m(self, script, params)\u001b[0m\n\u001b[0;32m     94\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedded\u001b[39m.\u001b[39mrun_script(script, params \u001b[39mor\u001b[39;00m {})\n\u001b[0;32m     95\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mraise\u001b[39;00m QueryException(e\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     97\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpandas:\n\u001b[0;32m     98\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpandas\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39mres[\u001b[39m'\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m'\u001b[39m], data\u001b[39m=\u001b[39mres[\u001b[39m'\u001b[39m\u001b[39mrows\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mQueryException\u001b[0m: index full_text_search for relation sentences not found"
     ]
    }
   ],
   "source": [
    "cozo_client.run(\"::index drop sentences:full_text_search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_id = \"000c652c-b424-4018-9921-a58da202b180\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>file_id</th>\n",
       "      <th>slide_i</th>\n",
       "      <th>sentence_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b2feaf75-811a-407c-9f1e-c73834271653</td>\n",
       "      <td>1a3df684b83b0d62b9b5d7bfe7de7d18692282b2082f97...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b4d4cf05-5f19-48e4-bb0a-bee08cf96050</td>\n",
       "      <td>1a3df684b83b0d62b9b5d7bfe7de7d18692282b2082f97...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>755aabca-83c1-4b66-af7c-0c0620eab8e4</td>\n",
       "      <td>1a3df684b83b0d62b9b5d7bfe7de7d18692282b2082f97...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            sentence_id  \\\n",
       "0  b2feaf75-811a-407c-9f1e-c73834271653   \n",
       "1  b4d4cf05-5f19-48e4-bb0a-bee08cf96050   \n",
       "2  755aabca-83c1-4b66-af7c-0c0620eab8e4   \n",
       "\n",
       "                                             file_id  slide_i  sentence_i  \n",
       "0  1a3df684b83b0d62b9b5d7bfe7de7d18692282b2082f97...        0           7  \n",
       "1  1a3df684b83b0d62b9b5d7bfe7de7d18692282b2082f97...        0           8  \n",
       "2  1a3df684b83b0d62b9b5d7bfe7de7d18692282b2082f97...        0           9  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# passages_slides {passage_id => file_id, slide_i, sentence_start, sentence_end}\n",
    "# slides_sentences {sentence_id => file_id, slide_i, sentence_i}\n",
    "cozo_client.run(\"\"\"\n",
    "    passage[file_id,slide_i, sentence_start, sentence_end] := *passages_slides[passage_id, file_id, slide_i, sentence_start, sentence_end] , passage_id=$passage_id\n",
    "    ?[sentence_id, file_id, slide_i, sentence_i] := *slides_sentences[sentence_id, file_id, slide_i, sentence_i], passage[file_id,slide_i, sentence_start, sentence_end], sentence_i>=sentence_start, sentence_i<sentence_end\n",
    "    :order file_id, slide_i, sentence_i\n",
    "    \"\"\", {\"passage_id\": passage_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_id = \"00494883-8483-49a5-86fc-3e34398af597\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e1988934-22fa-4940-b0fb-6f45e8376448',\n",
       " 'e2b82913-d10b-48b7-adcf-564eeb73897c',\n",
       " 'a182aaf0-2873-4f78-b06d-d4f7c87c4417']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cozo_client.run(\"\"\"\n",
    "            passage[file_id, start_time_p, end_time_p] := *passages_videos[passage_id, file_id, start_time_p, end_time_p] , passage_id=$passage_id\n",
    "            ?[sentence_id, file_id, start_time, end_time] := *videos_sentences[sentence_id, file_id, start_time, end_time], passage[file_id, start_time_p, end_time_p], start_time>=start_time_p, end_time<end_time_p\n",
    "            :order file_id, start_time\n",
    "            \"\"\", {\"passage_id\": passage_id}).sentence_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_ids = ['3a51a2ef-c6f2-4bd7-9113-7100a6e0ea7e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_id => sentence, type:String\n",
    "# order by a list of sentence_ids \n",
    "sentences = cozo_client.run(\"\"\"\n",
    "    ?[sentence_id, sentence,type] := *sentences[sentence_id, sentence, type], sentence_id in $sentence_ids\n",
    "    \"\"\", {\"sentence_ids\": sentence_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3a51a2ef-c6f2-4bd7-9113-7100a6e0ea7e</td>\n",
       "      <td>To illustrate this procedure, assume we have 4...</td>\n",
       "      <td>kadzinski_notes_pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            sentence_id  \\\n",
       "0  3a51a2ef-c6f2-4bd7-9113-7100a6e0ea7e   \n",
       "\n",
       "                                            sentence                 type  \n",
       "0  To illustrate this procedure, assume we have 4...  kadzinski_notes_pdf  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There will be communities that are under represented. The problem is that it's sometimes really very hard to to find out that a group has been stereotyped by the language model. As a matter of fact, the this this is caused by the fact that the only ones who really have the expertise to find stereotypes and to say, well, this is stereotypical.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_passage = \" \".join([sentences[sentences.sentence_id == sentence_id].sentence.values[0] for sentence_id in sentence_ids])\n",
    "total_passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cozo_client.run(\"\"\"\n",
    "            passage[file_id, start_time, end_time] := *passages_videos[passage_id, file_id, start_time, end_time] , passage_id=$passage_id\n",
    "            ?[sentence_id, file_id, start_time, end_time] := *video_sentences[sentence_id, file_id, start_time, end_time], passage[file_id, start_time, end_time], sentence_i>=start_time, sentence_i<end_time\n",
    "            :order file_id, start_time\n",
    "            \"\"\", {\"passage_id\": passage_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['49e7e0c4-8735-43bd-adb2-78456a96696b', 'video',\n",
       "        'Or, for instance, if we are doing the name entity recognition, then we have to find the demarc ation of the entity span.'],\n",
       "       ['59ab0a9b-a923-4eb9-8664-dfd2c967877a', 'video',\n",
       "        'Having some experts selected, we can start solving our main tasks. We can start annot ating. We can ask our experts , for example, to mark all fragments of texts which refer to the names of companies, dates and mentions about people as this might be a basis of our great named entity recognition tool we produce . So we provide them with guidelines on what they should do and give them access to our data set.'],\n",
       "       ['5b52a1c9-9fe5-492b-a0fe-778c7f0a6b3c', 'video',\n",
       "        'And prompt learning can do knowledge prob ing, can do question answering, it can classify the text, it can extract information like name entity recognition for instance, or entity linking, it can do reasoning in N LP, for instance , the natural language inference task, it can generate tasks, it can even do multim odal learning where you have for instance images and text .'],\n",
       "       ['6401f9e5-b35e-491c-ab0b-387b2e5288a8', 'video',\n",
       "        'Part of speech tagging is very similar to named entity recognition in which we tag each of the words using parts of speech tags. We can even mark relations between tokens, like in the case of relations and spans.'],\n",
       "       ['73debac7-35b2-45e5-b88a-700ac0724cbe', 'video',\n",
       "        'Experts have to read a given document and label to it . The data set preparation in the context of named entity recognition is much more tricky, as asking experts to mark fragments of texts using mouse can be error prone.'],\n",
       "       ['86306cb0-cb15-4c61-aca4-10d36d29baf1', 'video',\n",
       "        'The most popular tasks solved are classification and named entity recognition tasks.'],\n",
       "       ['a35771a7-ae41-4d77-bb19-6be313df1fc5', 'video',\n",
       "        'For instance, the test classification, or sentiment classification, or name entity recognition, or entity linking, or whatever.'],\n",
       "       ['ab1ad507-68d6-41c7-b2f9-a8c982a550dc', 'video',\n",
       "        'However, as we observed thousands of examples, we might change our minds so that it is not a rare scenario in which if a given example is provided at the beginning of annotation process and at the end of the annotation process to the same person, the decisions might differ, especially in those hard edge cases. For instance, if we have to tag spam emails, our understanding of what spam is might evolve as we look at those documents . So it might be a good idea to provide periodically some already annotated documents to the same person to measure whether the concept that they want to annotate changed in their minds or not. This way we can spot some moments where a big change was made so that maybe it was to annotate a given data set one more time when I give an annot ator. Regarding the annotation procedure itself, there are various tools that can be used like Prodigy, which allows us to solve various tasks such as text classification, image classification, multi-choice selection, named entity recognition, etc. However, Prodigy is not free. We have to pay for it.']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cozo_client.run(\n",
    "        \"\"\"\n",
    "        ?[sentence_id, type, sentence] := ~sentences:full_text_search {sentence_id,type, sentence |\n",
    "            query: $query,\n",
    "            k: 15\n",
    "        }\n",
    "        \"\"\",\n",
    "        {\"query\": \"named entity recognition\"}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cozo_client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read docs\n",
    "paths = [\n",
    "    r\"../assets/text/da-lec1-notes.txt\",\n",
    "    r\"../assets/text/da-lec2-notes.txt\",\n",
    "    r\"../assets/text/da-lec3-notes.txt\",\n",
    "    r\"../assets/text/da-lec4-notes.txt\",\n",
    "    r\"../assets/text/da-lec5-notes.txt\",\n",
    "    r\"../assets/text/da-lec6-notes.txt\",\n",
    "    r\"../assets/text/da-lec7-notes.txt\",\n",
    "    r\"../assets/text/da-lec8-notes.txt\",\n",
    "    r\"../assets/text/da-lec9-notes.txt\",\n",
    "    r\"../assets/text/da-lec10-notes.txt\",\n",
    "    r\"../assets/text/da-lec11-notes.txt\",\n",
    "    r\"../assets/text/da-lec12-notes.txt\",\n",
    "]\n",
    "from pathlib import Path\n",
    "\n",
    "paths = [Path(p) for p in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "document_relation = pd.DataFrame(\n",
    "    columns=[\"document_name\",\"document_path\"],\n",
    "    data=[(path.name, path) for i, path in enumerate(paths)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client('sqlite', 'file.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = client.run(\"\"\"\n",
    "\n",
    "?[sentence, paragraph_id, doc_name] := ~sentence:phrases {paragraph_id,doc_name, sentence |\n",
    "\n",
    " query: $query,\n",
    "\n",
    " k: 1000\n",
    "\n",
    " }\n",
    "\"\"\", {\"query\": f\"NEAR/1(dominating strategy)\"})\n",
    "d.to_markdown(\"example.md\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a document path - document id relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  status\n",
       "0     OK"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.run(\n",
    "    \"\"\"\n",
    "    :create document {document_name => document_path}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document_name, document_path in document_relation.values:\n",
    "    client.run(\"\"\"\n",
    "    ?[document_name, document_path] <- [[$document_name, $document_path]]\n",
    "    :put document {document_name => document_path}\n",
    "    \"\"\",{\"document_name\":str(document_name),\"document_path\":str(document_path)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  status\n",
       "0     OK"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.run(\"\"\"\n",
    "    :create sentence {sentence_id, paragraph_id, doc_name => sentence} \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  status\n",
       "0     OK"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.run(\"\"\"\n",
    "    :create phrases {phrase:String, doc_name:String, paragraph_id:Int?}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['da-lec8-notes.txt.txt', 'da-lec9-notes.txt.txt', 'da-lec10-notes.txt.txt', 'da-lec11-notes.txt.txt', 'da-lec12-notes.txt.txt'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read phrases \n",
    "import json\n",
    "with open(r\"../data/annotated_decision_analysis.json\",\"r\") as f:\n",
    "    phrases = json.load(f)\n",
    "phrases = {k+\".txt\":v for k,v in phrases.items()}\n",
    "phrases.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_dict = {\n",
    "    \"sentence\": {\n",
    "        \"headers\": [\"sentence_id\", \"paragraph_id\", \"doc_name\", \"sentence\"],\n",
    "        \"rows\": [],\n",
    "    }\n",
    "}\n",
    "for path in paths:\n",
    "    with open(path, 'r') as f:\n",
    "        paragraphs = f.read().splitlines()\n",
    "    doc_name = path.name\n",
    "    doc_path = path\n",
    "    for paragraph_id,paragraph in enumerate(paragraphs):\n",
    "        if len(paragraph) > 0:\n",
    "            sents = sent_tokenize(paragraph)\n",
    "            for sentence_id, sent in enumerate(sents):\n",
    "                sentence_dict[\"sentence\"][\"rows\"].append(\n",
    "                    [sentence_id, paragraph_id, doc_name, sent]\n",
    "                )\n",
    "\n",
    "# sentence_dict\n",
    "client.import_relations(sentence_dict)\n",
    "\n",
    "# tx.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  status\n",
       "0     OK"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.run(\"\"\"\n",
    "    ::fts create sentence:phrases {\n",
    "    extractor: sentence,\n",
    "    tokenizer: Simple,\n",
    "    filters: [Lowercase,AlphaNumOnly, Stemmer('English')],\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "phrases: 100%|██████████| 431/431 [00:03<00:00, 131.73it/s]\n"
     ]
    }
   ],
   "source": [
    "phrase_dict = {\n",
    "    \"phrases\": {\n",
    "        \"headers\": [\"phrase\", \"doc_name\", \"paragraph_id\"],\n",
    "        \"rows\": []\n",
    "    }\n",
    "}\n",
    "all_phrases = [phrase for doc_phrases in phrases.values() for phrase in doc_phrases]\n",
    "all_phrases = list(set(all_phrases))\n",
    "for original_phrase in tqdm(all_phrases,desc=\"phrases\",total=len(all_phrases)):\n",
    "    #replace non alphanumeric characters with space\n",
    "    phrase = \"\".join([c if c.isalnum() else \" \" for c in original_phrase])\n",
    "    # split phrase into 2 word spans\n",
    "    phrase = phrase.split()\n",
    "    span = \" \".join(phrase[0:2])\n",
    "\n",
    "    total = client.run(\"\"\"\n",
    "        ?[paragraph_id, doc_name] := ~sentence:phrases {paragraph_id,doc_name, sentence |\n",
    "            query: $query,\n",
    "            k: 1000\n",
    "        }\n",
    "        \"\"\", {\"query\": f\"NEAR/1({span})\"})\n",
    "    \n",
    "    for i in range(1,len(phrase)-1):\n",
    "        span = \" \".join(phrase[i:i+2])\n",
    "        results = client.run(\"\"\"\n",
    "        ?[paragraph_id, doc_name] := ~sentence:phrases {paragraph_id,doc_name, sentence |\n",
    "            query: $query,\n",
    "            k: 1000\n",
    "        }\n",
    "        \"\"\", {\"query\": f\"NEAR/1({span})\"})\n",
    "        total = pd.merge(total,results,how=\"inner\")\n",
    "    for paragraph_id, doc_name in total.values:\n",
    "        phrase_dict[\"phrases\"][\"rows\"].append([original_phrase, doc_name, paragraph_id])\n",
    "        \n",
    "client.import_relations(phrase_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama paradox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arrow 's theorem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baldwin method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Banzhaf power index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>weighted majority graph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>weighted sum method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>weighted voting games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>winner-turns-loser paradox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>winning coalition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>430 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        phrases\n",
       "0                           ASF\n",
       "1               Alabama paradox\n",
       "2              Arrow 's theorem\n",
       "3                Baldwin method\n",
       "4           Banzhaf power index\n",
       "..                          ...\n",
       "425     weighted majority graph\n",
       "426         weighted sum method\n",
       "427       weighted voting games\n",
       "428  winner-turns-loser paradox\n",
       "429           winning coalition\n",
       "\n",
       "[430 rows x 1 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.run(\"\"\"\n",
    "    ?[phrases] := *phrases[phrases, doc_name, paragraph_id]\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/kryst/Documents/Personal/university/ai_sem6/nlp/testing')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_path = Path(r\"C:\\Users\\kryst\\Documents\\Personal\\university\\ai_sem6\\nlp\\testing\")\n",
    "notes_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dictatorship'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paragraphs(original_phrase):\n",
    "    dataframe = client.run(\"\"\"\n",
    "        paragraphs[doc_name, paragraph_id] := *phrases[$phrase, doc_name, paragraph_id],\n",
    "        ?[sentence,sentence_id,paragraph_id,doc_name] := *sentence[sentence_id, paragraph_id, doc_name, sentence],paragraphs[doc_name, paragraph_id]\n",
    "        :order doc_name, paragraph_id, sentence_id\n",
    "        \"\"\",{\"phrase\":original_phrase})\n",
    "    # for each combination of paragraph_id and doc_name, get the paragraph\n",
    "    return dataframe.groupby([\"doc_name\",\"paragraph_id\"]).agg({\"sentence\":lambda x: \" \".join(x)})\n",
    "    \n",
    "    \n",
    "df = get_paragraphs(\"dictatorship\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('da-lec10-notes.txt', 12),\n",
       "  sentence     At this stage, you already know some properti...\n",
       "  Name: (da-lec10-notes.txt, 12), dtype: object),\n",
       " (('da-lec10-notes.txt', 13),\n",
       "  sentence     Now is the time to present the most famous th...\n",
       "  Name: (da-lec10-notes.txt, 13), dtype: object),\n",
       " (('da-lec10-notes.txt', 21),\n",
       "  sentence     Before we discuss another central result in v...\n",
       "  Name: (da-lec10-notes.txt, 21), dtype: object),\n",
       " (('da-lec10-notes.txt', 28),\n",
       "  sentence     To sum up what we have discussed so far, an a...\n",
       "  Name: (da-lec10-notes.txt, 28), dtype: object)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_name</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">da-lec10-notes.txt</th>\n",
       "      <th>12</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 sentence\n",
       "doc_name           paragraph_id          \n",
       "da-lec10-notes.txt 12                True\n",
       "                   13                True\n",
       "                   21                True\n",
       "                   28                True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"doc_name\",\"paragraph_id\"]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "notes: 100%|██████████| 431/431 [00:30<00:00, 14.29it/s]\n"
     ]
    }
   ],
   "source": [
    "for original_phrase in tqdm(all_phrases, desc=\"notes\", total=len(all_phrases)):\n",
    "    md_text = \"\"\n",
    "    paragraphs = get_paragraphs(original_phrase)\n",
    "    for paragraph_description,paragraph in paragraphs.iterrows():\n",
    "        md_text += f\"\\n\\n `document : {paragraph_description[0]} slide: {paragraph_description[1]}`\"\n",
    "        md_text += f\"\\n\\n {paragraph['sentence']}\"\n",
    "    md_text += \"\\n\\n## See also:\"\n",
    "    adjacent = client.run(\"\"\"\n",
    "        ?[phrase] := *phrases[phrase, doc_name, paragraph_id], *phrases[$phrase, doc_name, paragraph_id], phrase!= $phrase\n",
    "        \"\"\",{\"phrase\":original_phrase}).values\n",
    "    for phrase in adjacent:\n",
    "        md_text += f\"\\n[[{phrase[0]}]]\"\n",
    "    cleaned_phrase = \"\".join([c if c.isalnum() else \" \" for c in original_phrase])\n",
    "    with open(notes_path / f\"{cleaned_phrase}.md\",\"w\") as f:\n",
    "        f.write(md_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagerank = client.run(\"\"\"\n",
    "        phrase_graph[phrase1,phrase2] := *phrases[phrase1, \"da-lec12-notes.txt\", paragraph_id], *phrases[phrase2, \"da-lec12-notes.txt\", paragraph_id], phrase1!= phrase2\n",
    "        ?[phrase,page_rank] <~ PageRank(phrase_graph[])\n",
    "        :order -page_rank\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>page_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi-objective optimization</td>\n",
       "      <td>0.024573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>objective optimization</td>\n",
       "      <td>0.024567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dominated solutions</td>\n",
       "      <td>0.023775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non-dominated solutions</td>\n",
       "      <td>0.023771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>evolutionary algorithm</td>\n",
       "      <td>0.022128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>recombination</td>\n",
       "      <td>0.021444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>genetic algorithm</td>\n",
       "      <td>0.020552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pareto frontier</td>\n",
       "      <td>0.018569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>crowding distance</td>\n",
       "      <td>0.016729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>reference point</td>\n",
       "      <td>0.016642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>optimization problem</td>\n",
       "      <td>0.016237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NSGA-II</td>\n",
       "      <td>0.015415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>optimal solution</td>\n",
       "      <td>0.014315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>objective function</td>\n",
       "      <td>0.014034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>genetic operator</td>\n",
       "      <td>0.013617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>archive</td>\n",
       "      <td>0.013289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tournament selection</td>\n",
       "      <td>0.013148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>selection scheme</td>\n",
       "      <td>0.013104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hypervolume</td>\n",
       "      <td>0.012431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>objective space</td>\n",
       "      <td>0.012237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          phrase  page_rank\n",
       "0   multi-objective optimization   0.024573\n",
       "1         objective optimization   0.024567\n",
       "2            dominated solutions   0.023775\n",
       "3        non-dominated solutions   0.023771\n",
       "4         evolutionary algorithm   0.022128\n",
       "5                  recombination   0.021444\n",
       "6              genetic algorithm   0.020552\n",
       "7                Pareto frontier   0.018569\n",
       "8              crowding distance   0.016729\n",
       "9                reference point   0.016642\n",
       "10          optimization problem   0.016237\n",
       "11                       NSGA-II   0.015415\n",
       "12              optimal solution   0.014315\n",
       "13            objective function   0.014034\n",
       "14              genetic operator   0.013617\n",
       "15                       archive   0.013289\n",
       "16          tournament selection   0.013148\n",
       "17              selection scheme   0.013104\n",
       "18                   hypervolume   0.012431\n",
       "19               objective space   0.012237"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pagerank.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_detection_louvain = client.run(\"\"\"\n",
    "        phrase_graph[phrase1,phrase2] := *phrases[phrase1, \"da-lec12-notes.txt\", paragraph_id], *phrases[phrase2, \"da-lec12-notes.txt\", paragraph_id], phrase1!= phrase2\n",
    "        ?[community_index,node_index] <~ CommunityDetectionLouvain(phrase_graph[])\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>community_index</th>\n",
       "      <th>node_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Chebyshev function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>MOEA/D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>evolutionary algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>multiple objective problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>objective problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>[6, 9]</td>\n",
       "      <td>evolved population</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>[6, 9]</td>\n",
       "      <td>preference information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>[6, 10]</td>\n",
       "      <td>generation model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>[6, 10]</td>\n",
       "      <td>population management models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>[6, 10]</td>\n",
       "      <td>steady-state model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    community_index                    node_index\n",
       "0            [0, 0]            Chebyshev function\n",
       "1            [0, 0]                        MOEA/D\n",
       "2            [0, 0]        evolutionary algorithm\n",
       "3            [0, 0]    multiple objective problem\n",
       "4            [0, 0]             objective problem\n",
       "..              ...                           ...\n",
       "114          [6, 9]            evolved population\n",
       "115          [6, 9]        preference information\n",
       "116         [6, 10]              generation model\n",
       "117         [6, 10]  population management models\n",
       "118         [6, 10]            steady-state model\n",
       "\n",
       "[119 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community_detection_louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_detection_louvain.to_csv(\"community_detection_louvain.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
